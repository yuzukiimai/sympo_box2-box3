\documentclass[twocolumn, 9pt]{jsproceedings}
\RequirePackage[l2tabu, orthodox]{nag}  % 古いコマンドやパッケージを使用した場合に警告する
\usepackage[all, warning]{onlyamsmath}  % amsmath が提供しない数式環境を使用した場合に警告する
\usepackage{flushend}  % 最終ページの2カラムの左右の高さを揃える



\usepackage{otf}
\usepackage[ipa]{pxchfon}
\usepackage{caption}
\usepackage{graphicx}

% タイトル
\title{つくばチャレンジ 2023 における\\千葉工業大学未来ロボティクス学科 box2，box3チームの取り組み}

\author{○今井 悠月，井口 颯人，樋高 聖人，春山 健太，藤原 柾，\CID{8705}橋 祐樹，白須 和暉，野村 駿斗，
望月 悠矢，\\馬場 琉生，村林 孝太郎，桜井 真希，中村 雄一，長島 昂生，\\上田 隆一，林原 靖男（千葉工大）}

\etitle{The activities of the Advanced Robotics Department box2 and box3 team of Chiba Institute of Technology in the Tsukuba Challenge 2023}

\eauthor{Yuzuki IMAI, Hayato IGUCHI, Masato HIDAKA, Kenta HARUYAMA, Masaki FUJIWARA, \\Yuki TAKAHASHI,
 Kazuki SHIRASU, Hayato NOMURA, Yuya MOCHIZUKI, Ryusei BABA, \\Koutarou MURABAYASHI, Maki SAKURAI,
 Yuichi NAKAMURA, Kousei NAGASHIMA, \\Ryuichi UEDA and Yasuo HAYASHIBARA (CIT)}

\affiliation{千葉工業大学未来ロボティクス学科 box2, box3チーム}

\abstract{
  In this paper, we present the activities of the Advanced Robotics Department box2 and box3 team of 
  Chiba Institute of Technology in the Tsukuba Challenge 2023. 
  We developed autonomous outdoor mobile robots, and we tackled several challenges. 
  For example, We developed robots using machine learning and robots that can run in the rain.
}


\begin{document}
\maketitle

% 本文
\section{緒言}
我々は，屋外でも正確に自律移動可能なロボットを目指し，その研究および開発の一環として
つくばチャレンジに参加している．
これまで本研究室\footnote{千葉工業大学未来ロボティクス学科 林原研究室}では，地図生成や自己位置推定を
中心に研究開発を行ってきた．近年では，防水機能や高い拡張性を有したオープンプラットフォームのロボットの
開発も行っている．
つくばチャレンジ2022では，開発したロボットやシステムを用いて，記録走行において完走した．
しかし，本年度からは確認走行エリアのコースが一部変更され，つくば市役所の外周がコースに含まれるように
なった．そのため，従来用いていた 30 m 程度の 2次元レーザレンジセンサ 1つでは，低層の茂みや障害物などを
検出しつつ，安定して自己位置推定を行うのが困難となった．
さらに，道幅の狭い経路を通る必要があるため，完走するにはよりロバストなシステムが求められるようになった．

本稿では，このような問題を解決するためにつくばチャレンジ2023に向けて取り組んだ内容を紹介する．

\section{開発中のロボット}
ロボットを常に屋外環境で走行させるためには，防水設計が求められる．ただし，防水性を担保しながら
ロボットの機構や電気回路の追加・変更を行うことは，作業の負担が大きく，多くの時間を要するため，
新たなアルゴリズムの開発や検証に十分な時間を割当てられないことが問題となっていた．

この問題を踏まえて，本研究室では屋外自律移動ロボットプラットフォーム ORNE-boxの開発を行ってきた\cite{box}．
日々検証と改良を重ねており，現在は，3台のロボット（ORNE-box，ORNE-box2，ORNE-box3）がある．
これらのロボットは，屋外での自律走行を目的としており，屋外自律走行の研究開発に必要な機能をパッケージ化
し，提供することを目標に開発を行っている．設計データなどは，ウェブページ上にて順次公開している\cite{box-data}．

ORNE-box2 は，ORNE-box の問題点を洗い出し改善を図るという方針のもと，昨年度から開発を行っている．
センサ構成などに差異はあるが，基本的なシステム構成は同じである．

ORNE-box3 は，今年度から開発を行っており，ORNE-box2 の防水性能や拡張性をさらに改善した設計となっている．

\subsection{ハードウェア}
ORNE-box-Series の外観を\figref{fig:orne-series}，仕様を\tableref{table:1}に示す．
これらのロボットは，i-Cart middle\cite{icart} をベースとしている．

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[width=21.1mm]{fig/box.pdf}
    \caption*{(a) ORNE-box}
  \end{minipage} 
  \hspace{-1.2mm}
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[height=34mm]{fig/box2.pdf}
    \caption*{(b) ORNE-box2}
  \end{minipage}
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[height=34mm]{fig/box3.pdf}
    \caption*{(c) ORNE-box3}
  \end{minipage}
  \caption{ORNE-box-Series}
  \label{fig:orne-series}
\end{figure}

\vspace*{-4mm}

\begin{table}[h!]
  \centering
    \caption{Specifications of the robots.}
    \label{table:1}
    \scalebox{0.73}{
    \begin{tabular}{|l||c|c|c|}  \hline
      & ORNE-box & ORNE-box2 & ORNE-box3 \\ \hline \hline
      Depth[mm] & \multicolumn{2}{c|}{600} & わからん \\ \hline
      Wide[mm] & \multicolumn{2}{c|}{506.5} & わからん \\ \hline
      Height[mm] & \multicolumn{2}{c|}{957} & わからん \\ \hline
      Wheel diameter[mm] & \multicolumn{3}{c|}{304}\\ \hline
      Battery & \multicolumn{3}{c|}{LONG WP14-12SE}\\ \hline
      Motor & \multicolumn{3}{c|}{Oriental motor TF-M30-24-3500-G15L/R}\\ \hline
      Driving system & \multicolumn{3}{c|}{Power wheeled steering}\\ \hline
      2D-LiDAR & None &  UTM-30LX-EW & None\\
      & & (HOKUYO) & \\ \hline
      3D-LiDAR & None & \multicolumn{2}{c|}{R-fans-16} \\
      & & \multicolumn{2}{c|}{(SureStar)}\\ \hline
      IMU & ADIS16465 & ADIS16470 & None\\ 
      & (Analog Devices) & (Analog Devices) & \\ \hline
      Camera & None & \multicolumn{2}{c|}{CMS-V43BK}\\ 
      & & \multicolumn{2}{c|}{(SANWA SUPPLY)}\\ \hline
      Computer & None & Jetson AGX Xavier & Jetson Orin NX\\ 
      & & (NVIDIA) & (NVIDIA)\\ \hline
    \end{tabular}
  }
  \end{table}


\subsection{ソフトウェア}
本研究室では，従来より ROS(Robot Operating System)のnavigation stack\cite{navigation}を基に開発された
システムであるorne\_navigation\cite{orne-navigation} と orne\_box\cite{orne-box} により，ロボットを自律走行させている．
\figref{fig:soft-fig}に開発しているロボットのソフトウェアを含むシステム構成を示す．
このシステムは，LiDARなど複数のセンサを用いた Monte Carlo Localization(MCL)により確率的に自己位置を推定し， 
経路計画に基づいて自律走行している．なお，両ソフトウェアは GitHubのopen-rdc\cite{open-rdc} で公開している．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/software.pdf}
  \caption{Structure of the system.}
  \label{fig:soft-fig}
\end{figure}

\vspace*{2mm}

\section{各ロボットごとの研究開発}
本研究室では，使用するロボットごとに研究開発の目的が異なる．つくばチャレンジ2023においては，
ORNE-box2を使用するチームとORNE-box3を使用するチームの2つに分かれて研究開発を行ってきた．
以降，それぞれのチームをbox2チーム，box3チームと呼ぶこととする．
本章では，各チームごとの取り組みを述べる．

\subsection{box2チームの取り組み}
box2チームは，つくばチャレンジ2022において，記録走行で完走している．しかし，本走行では道路端で
一時停止に失敗し，記録は 320[m]であった．一時停止失敗の原因としては，自己位置推定の破綻が挙げられる．
ORNE-box2では，本走行前日にロボットの制御に使用していたコンピュータである Jetson AGX Xavier が
起動しなくなるトラブルが発生したため，急遽 GIGABYTE GB-BXi7H-4500 に交換を行っていた．
これにより計算処理が間に合わなかったおそれがある．

よって本年度は，基本的には昨年度と同じシステムを用いて完走することを目的とした．
なお，制御用のコンピュータには，記録走行完走時に用いていた Jetson AGX Xavier を使用した．
本年度の取り組みを以下で紹介する．

\subsubsection{センサ・システム構成}
box2チームは，\figref{fig:box2-sensor}のように LiDAR，ホイールエンコーダ，IMU，RGBカメラというセンサ構成で実験走行および本走行に臨んだ．
特徴としては，2つの LiDAR を用いている点が挙げられる．
上部は自己位置推定用，下部は障害物回避用と使い分けることで，自己位置推定を正確に行いつつ，
低層の障害物などを検出して回避するという狙いがある．ここで，上部に取り付けた LiDAR は，3D-LiDAR であるが，
pointcloud\_to\_laserscan\cite{pointcloud} により，得られた3次元点群を圧縮し，2次元の点群として利用した．
また，ロボットの上部に取り付けたカメラは，選択課題 D1 に取り組む際に使用した．\\

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/box2_sensor.pdf}
  \caption{The sensor configuration of the box2 team.}
  \label{fig:box2-sensor}
\end{figure}


さらに，自律走行時のシステム構成を以下に示す．

\begin{itemize}
  \item 自己位置推定パッケージ：emcl2\cite{emcl2}
  \item センサ情報統合パッケージ：robot\_localization\cite{robotlocalization}
  \item waypoint パッケージ：waypoint\_manager\cite{waypoint}
  \item global planner：dijkstra
  \item local planner：TrajectoryPlannerROS
  \item map
\end{itemize}


\subsubsection{地図生成}
自律走行時に使用する地図の作成には，Cartographer\cite{Cartographer}を用いた．
ここで，本走行において使用した占有格子地図を\figref{fig:map}，\figref{fig:costmap}に示す．
\figref{fig:map}は，自己位置推定に使用する地図であり，基本的には作成時のものから手を加えていない．
\figref{fig:costmap}は，経路計画に用いる地図である．\figref{fig:map}の自己位置推定に用いる地図に
侵入不可能な領域を設定している．これにより，ロボットは侵入不可能領域以外で
経路を生成するようになる．さらに，領域を囲うことで，経路を計算する領域が減るため，
コンピュータの負荷を減らすことができる．
これらの地図は，確認走行エリア，その先から信号あり横断歩道，公園エリアのそれぞれで作成した
地図を合成している．地図の合成や編集には，GIMP\cite{gimp}を用いた．
ちなみに，resolutionは 0.10[m/pixel]で，ファイルのサイズは 17.8 MBであった．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/map.pdf}
  \caption{Map used for localization.}
  \label{fig:map}
\end{figure}
\vspace*{-2mm}
\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/costmap.pdf}
  \caption{Map used for planning.}
  \label{fig:costmap}
\end{figure}


%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsubsection{選択課題 D1}
box2チームでは，本年度から新しく追加された選択課題D1にも取り組んだ．
ここで，課題の概要を述べる．本課題は以下の流れで行う．

\vspace*{1mm}

1）集荷ボックス\figref{fig:hako} (a)の待機列に整列

2）白線を認識し，その手前 1[m]以内で一時停止

3）オペレータ操作により走行再開

4）集荷ボックスに50[cm]まで接近し，3秒以上停止

5）配達先ラベルを認識し，90秒以内に移動

6）指定の宅配ボックス\figref{fig:hako} (b)を探索

7）指定の宅配ボックスに50[cm]まで接近し，3秒以上停止
\begin{figure}[h!]
  \begin{minipage}[t]{0.47\linewidth}
    \centering
    \includegraphics[width=44.94mm]{fig/syuuka.pdf}
    \caption*{\hspace*{3mm}(a) Collection box}
  \end{minipage}
  \hspace*{2mm}
  \begin{minipage}[t]{0.47\linewidth}
    \centering
    \includegraphics[width=44.21mm]{fig/takuhai.pdf}
    \caption*{(b) Delivery box}
  \end{minipage}
  \caption{Examples of collection and delivery boxes. (source:\cite{tukuba})}
  \label{fig:hako}
\end{figure}\vspace*{-2mm}
次に，本課題のために取り組んだ内容を以下に述べる．

\begin{itemize}
  \setlength{\leftskip}{-1zw}
  \item 集荷ボックス，宅配ボックス，配達先の認識
\end{itemize}
\vspace*{-2.5mm}

各ボックスや配達先の認識には，YOLOv5\cite{yolo}を用いた．YOLOは画像を入力とし，対象物が
画像中のどこにあるかを表すバウンディングボックスと認識率を出力する．
データセットは自作のものを使用した．作成したデータセットは\cite{nagashima}で公開している．
作成の手順としては，まず ORNE-box2の上部に取り付けたカメラを使用し，現地と千葉工業大学津田沼キャンパスで
画像を収集した．
次に，収集した画像にボックス 2つ(集荷，宅配)と配達先 3つ(a,b,c)の計5 クラスでラベル付けをした．
合計2287個のデータセットを作成し，そのうちの2261個を訓練用，26個を検証用とした．
訓練後は，訓練済みモデルを用いてボックスと配送先が認識できるかを検証した．
ここで，検証結果の一例を\figref{fig:test1}，\figref{fig:test2}に示す．
\figref{fig:test1}のように，屋内環境かつ近距離であれば，どちらも高い正確度で認識できた．
しかし，\figref{fig:test2}の例では配達先を誤認識した．
その原因としては\figref{fig:test1}の例に比べて，対象物とロボットの距離があることや，屋外の
日照条件の変化によって，収集した画像との差が発生したことが考えられる．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/test1.pdf}
  \caption{Recognition results in indoor.}
  \label{fig:test1}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/test2.pdf}
  \caption{Recognition results in real environment.}
  \label{fig:test2}
\end{figure}

\begin{itemize}
  \setlength{\leftskip}{-1zw}
  \item ロボットの行動決定
\end{itemize}
\vspace*{-2.5mm}

指定のボックスへの移動や近づいた後の停止処理，認識後の行動決定などに関して述べる．
ロボットは\figref{fig:hako_act}に示すようなシステムに基づき行動する．
本システムは，YOLOからのタグの認識結果に応じて，配達先を決定している．
配達先a,b,cすべてにウェイポイントを配置し，認識結果に応じてウェイポイントをスキップするという実装とした．
行動を開始するための条件はwaypointにあらかじめフラグを設定し，フラグが真のwaypointに到達することとした．
waypointに到達したときにボックスに近づくプログラムを開始した．
ボックスへの接近は，YOLOの出力であるバウンディングボックスの座標に基づき行われる．具体的には，対象の
ボックスが常にカメラ画像の中心に来るように速度指令値をロボットに送る．この速度指令値はyolo\_velという
名前のトピックで配信される．ボックスに近づいたと判断する指標は，LiDARの走査線である。
LiDARの走査線の配列中の指定した値が一定値以下になったら，ロボットとボックスが 50[cm]近づいたと判断して停止
する．ただし，ナビゲーションの起動中は，move\_baseに基づく速度指令値であるnav\_velという名前のトピック
が配信されており，そのままだと速度指令値が競合するため，どちらの速度指令値を使用するかをtwist\_muxに
よって判断し，cmd\_velという名前のトピックで配信している．
ここで，本システムを用いた実験の様子を\figref{fig:action}に示す．
結果的に，集荷ボックスへの接近と50[cm]以内で停止はできたが，走行再開後に宅配ボックスを発見したものの認識が行動の
途中で途切れてしまった．その対策としては，認識が途切れてから数秒以内は行動させ続けるというデッドタイムを設ける方法が考えられる．
なお，本システムは検証段階であったため，本走行では使用していない．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/act.pdf}
  \caption{Summary of the developed system.}
  \label{fig:hako_act}
\end{figure}




\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[width=31mm]{fig/1.pdf}
    \caption*{\hspace*{2.5mm}(a) Found the box}
  \end{minipage} 
  \hspace*{2.8mm}
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[height=22.9mm]{fig/2.pdf}
    \caption*{\hspace*{1.1mm}(b) White line stop}
  \end{minipage}
  \hspace*{0.5mm}
  \begin{minipage}[b]{0.3\linewidth}
    \centering
    \includegraphics[height=22.9mm]{fig/3.pdf}
    \caption*{\hspace*{3mm}(c) Stop near box}
  \end{minipage}
  \caption{Verification of the developed system.}
  \label{fig:action}
\end{figure}




%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



\subsubsection{本走行の結果}
box2チームの本年度の本走行の記録は，715[m]であった．
リタイアした地点は，公園前の信号機あり横断歩道である．
\figref{fig:box2-result}に示すように，本来は一時停止が必要な場所で，ロボットが道路端からはみ出した．
原因としては，自己位置推定の破綻が挙げられる．信号機周辺は他チームのロボットや通行人，自動車など，
環境がその都度大きく変化するため，作成した地図とマッチングしない，あるいは誤った場所でのマッチング
が起こったのではないかと考えられる．
なお box2チームは，8月18日に実施されたつくばチャレンジ2023EX＠イーアスつくば本走行にて完走している．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/result_box2_cut.pdf}
  \caption{The location where the box2 team failed.}
  \label{fig:box2-result}
\end{figure}

\subsection{box3チームの取り組み}
ここからはまだ手をつけていませんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんんん
ROS2 Dockerなど、、、
本年度の取り組みを以下で紹介する．

\subsubsection{センサ・システム構成}
box3 チームは，LiDAR，ホイールエンコーダ，RGBカメラというセンサ構成で実験走行および本走行に臨んだ．
box2 チームとは異なり，使用した LiDARは 1つである．
ここで，LiDAR は，3D-LiDAR であるが，
3次元点群を圧縮し，2次元の点群として利用している．
また，ロボットの上部に取り付けたカメラは，信号認識に取り組む際に使用した．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/box3_sensor.pdf}
  \caption{The sensor configuration of the box3 team.}
  \label{fig:box3-sensor}
\end{figure}


さらに，自律走行時のシステム構成を以下に示す．

\begin{figure}[h!]
  \centering
  \includegraphics[width=90mm]{fig/box3_system.pdf}
  \caption{The sensor configuration of the box3 team.}
  \label{fig:box3-system}
\end{figure}


\subsubsection{信号認識}
ああああああ

\begin{figure}[h!]
  \begin{minipage}[t]{0.47\linewidth}
    \centering
    \includegraphics[width=45mm]{fig/blue_cut.pdf}
    \caption*{(a) ORNE-box2}
  \end{minipage}
  \hspace*{2mm}
  \begin{minipage}[t]{0.47\linewidth}
    \centering
    \includegraphics[width=45mm]{fig/red_cut.pdf}
    \caption*{(b) ORNE-box2}
  \end{minipage}%\vspace*{2mm}
  \caption{Number of return to path}
\end{figure}

\subsubsection{本走行の結果}
ああああ
box3の本走行の記録は13[m]だったちきしょー
記録走行では431[m]



\section{結言}
本稿では，千葉工業大学未来ロボティクス学科 box2，box3チームで開発しているロボットとシステムの構成に
関して述べた．また，つくばチャレンジ2023に向けた取り組みについて紹介した．\\

\section*{謝辞}
つくばチャレンジ実行委員会の皆様およびつくば市の皆様に感謝申し上げます．また，上田研究室の皆様には
つくばチャレンジ2023の参加にあたり，ご意見やご協力をいただき感謝申し上げます．\\


% 参考文献
% \small
\footnotesize
\begin{thebibliography}{99}

\bibitem{box}
井口 颯人, 石江 義規, 樋高 聖人, 上田 隆一, 林原 靖男　: “ 屋外自律移動ロ
ボットプラットフォーム ORNE-box の開発 ”, 3H2-03 , SI2021(2021)

\bibitem{box-data}
open-rdc, orne-box, wiki\\
\url{https://github.com/open-rdc/orne-box/wiki}\\
(最終閲覧日：\today)

\bibitem{icart}
T-frog Project\\
\url{https://t-frog.com/forums/forum.php?ml=icart-mini-devel}\\
(最終閲覧日：\today)

\bibitem{navigation}
ros-planning, navigation リポジトリ\\
\url{https://github.com/ros-planning/navigation}\\
(最終閲覧日：\today)

\bibitem{orne-navigation}
open-rdc, orne\_navigation リポジトリ\\
\url{https://github.com/open-rdc/orne_navigation}\\
(最終閲覧日：\today)

\bibitem{orne-box}
open-rdc, orne-box リポジトリ\\
\url{https://github.com/open-rdc/orne-box}\\
(最終閲覧日：\today)

\bibitem{open-rdc}
Robot Design and Control Lab, open-rdc, リポジトリ\\
\url{https://github.com/open-rdc}\\
(最終閲覧日：\today)

\bibitem{pointcloud}
ROS wiki, pointcloud\_to\_laserscan\\
\url{https://wiki.ros.org/pointcloud_to_laserscan}\\
(最終閲覧日：\today)

\bibitem{emcl2}
ryuichiueda, emcl2 リポジトリ\\
\url{https://github.com/ryuichiueda/emcl2}\\
(最終閲覧日：\today)

\bibitem{robotlocalization}
cra-ros-pkg, robot\_localization リポジトリ\\
\url{https://github.com/cra-ros-pkg/robot_localization}\\
(最終閲覧日：\today)

\bibitem{waypoint}
masakifujiwara1, waypoint\_manager リポジトリ\\
\url{https://github.com/masakifujiwara1/waypoint_manager}\\
(最終閲覧日：\today)

\bibitem{Cartographer}
cartographer-project, cartographer リポジトリ\\
\url{https://github.com/cartographer-project/cartographer}\\
(最終閲覧日：\today)

\bibitem{gimp}
GIMP 公式ドキュメント\\
\url{https://www.gimp.org/}\\
(最終閲覧日：\today)

\bibitem{tukuba}
つくばチャレンジ 2023 公式サイト\\
\url{https://tsukubachallenge.jp/2023/}\\
(最終閲覧日：\today)

\bibitem{yolo}
ultralytics, yolov5 リポジトリ\\
\url{https://github.com/ultralytics/yolov5}\\
(最終閲覧日：\today)

\bibitem{nagashima}
NagashimaKousei, Tsukuba\_Delivery リポジトリ\\
\url{https://github.com/NagashimaKousei/Tsukuba_Delivery}\\
(最終閲覧日：\today)



\end{thebibliography}
\normalsize

\end{document}
